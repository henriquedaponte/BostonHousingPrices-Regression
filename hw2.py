import numpy as np
import pandas as pd
import cvxpy as cp

# ====================== Utility Functions ======================

def meanSquaredError(predicted, actual):
    '''
    Calculate the mean squared error (MSE) between predicted and actual values.
    
    Parameters:
    - predicted (numpy array): The array of predicted values generated by the model.
    - actual (numpy array): The array of actual or true values.
    
    Returns:
    - int: The mean squared error, rounded to the nearest whole number, between the predicted and actual values.
    
    Notes:
    The mean squared error is computed as the average of the squared differences between predicted and actual values.
    '''
    
   # Ensure that predicted array is not empty
    if len(predicted) == 0:
        raise ValueError("Predicted array is empty.")
        
    # Ensure that there are no NaN values in predicted and actual arrays
    if np.isnan(predicted).any() or np.isnan(actual).any():
        raise ValueError("NaN values detected in input arrays.")
    
    r = actual - predicted # Residuals
    mse = np.sum(r**2) / len(predicted)
    
    return round(mse)

def preprocessData(filename, trainDataPct):
    '''
    Preprocesses the data by loading it and dividing it into training and test sets.
    
    Parameters:
    - filename (str): Path to the input data file.
    - trainDataPct (float): Percentage of data to be used for training (e.g., 0.7 for 70%).
    
    Returns:
    - tuple: 
        - X_train (numpy array): Training data attributes.
        - Y_train (numpy array): Training data target values.
        - X_test (numpy array): Test data attributes.
        - Y_test (numpy array): Test data target values.
    '''
     
    data = pd.read_csv(filename, delimiter='\t')

    # Using trainDataPct% of the data for training
    trainDataSize = int(trainDataPct * data.shape[0])
    trainData = data.iloc[:trainDataSize, :]
    X_train = trainData.iloc[:, :-1].values
    Y_train = (trainData.iloc[:, -1].values).reshape(-1, 1)

    # Using testDataPct% of the data for testing 
    testData = data.iloc[trainDataSize:, :]
    X_test = testData.iloc[:, :-1].values
    Y_test = (testData.iloc[:, -1].values).reshape(-1, 1)

    return X_train, Y_train, X_test, Y_test
    
def trainLinearModel(X_train, Y_train):
    ''''
    Trains a linear regression model using CVX optimization.
    
    Parameters:
    - X_train (numpy array): Training data attributes.
    - Y_train (numpy array): Training data target values.
    
    Returns:
    - tuple:
        - Ytrain_pred (numpy array): Predicted values for the training data.
        - beta (numpy array): Learned coefficients for the attributes.
        - alpha (float): Learned intercept term.
    '''

    # Initilizing decision variables
    alpha = cp.Variable()
    beta = cp.Variable((X_train.shape[1], 1))

    # Defining function for our predictions
    Ytrain_pred = alpha + X_train @ beta

    # Defining objective function
    objective = cp.Minimize(cp.sum_squares(Y_train - Ytrain_pred))

    # Formulating problem
    problem = cp.Problem(objective)

    # solving the problem
    problem.solve()

    return Ytrain_pred.value, beta.value, alpha.value

def trainL1Model(X_train, Y_train):
    ''''
    
    
    Parameters:
    
    
    Returns:
    
    '''

    # Initilizing decision variables
    beta = cp.Variable((X_train.shape[1], 1))

    # Defining function for our predictions
    Ytrain_pred = X_train @ beta

    # Defining objective function
    objective = cp.Minimize(cp.sum(cp.abs(Y_train - Ytrain_pred)))

    # Formulating problem
    problem = cp.Problem(objective)

    # solving the problem
    problem.solve()

    return Ytrain_pred.value, beta.value, 0

def trainPolynomialModel(X_train, Y_train):
    '''
    Trains a polynomial regression model using CVX optimization.
    
    Parameters:
    - X_train (numpy array): Training data attributes.
    - Y_train (numpy array): Training data target values.
    
    Returns:
    - tuple:
        - Ytrain_pred (numpy array): Predicted values for the training data.
        - betas (numpy array): Learned coefficients for the attributes.
        - alpha (float): Learned intercept term.
    '''

    num_features = X_train.shape[1]

    # Generating polynomial terms for the input features
    X_poly = np.hstack([X_train, X_train**2, X_train**3])
    
    # Initializing decision variables
    alpha = cp.Variable()
    betas = cp.Variable((3 * num_features, 1))
    
    # Defining function for our predictions
    Ytrain_pred = alpha + X_poly @ betas

    # Defining objective function
    objective = cp.Minimize(cp.sum_squares(Y_train - Ytrain_pred))

    # Formulating problem
    problem = cp.Problem(objective)

    # Solving the problem
    problem.solve(solver=cp.SCS)

    return Ytrain_pred.value, betas.value, alpha.value

def deployModel(filename, split, trainMethod, modelName, poly=False):
    '''
    Trains a regression model on a given dataset and computes the mean squared error for both training and test data.
    
    Parameters:
    - filename (str): Path to the input data file.
    - split (float): Percentage (expressed as a decimal, e.g., 0.3 for 30%) of data to be used for training.
    - trainMethod (function): A function that trains the model. This function should return predicted values for the training set, coefficients for the attributes, and an intercept term.
    - modelName (str): A descriptive name for the model which will be used in print statements.
    - poly (bool, optional): If True, the function assumes the model is polynomial and will generate polynomial terms for the test data. Default is False.
    
    Returns:
    None
    
    Outputs:
    The function prints the mean squared error for the training data and test data. 
    
    Notes:
    - This function assumes the input data file is tab-delimited and the target values are in the last column.
    - The preprocessData function is used to split the data and should be defined elsewhere in the code.
    - If 'poly' is set to True, the function will generate polynomial terms up to the third degree for the test data.
    
    Example:
    deployModel('data.txt', 0.3, trainLinearModel, "Linear Regression")
    deployModel('data.txt', 0.3, trainPolynomialModel, "Polynomial Regression", poly=True)
    '''

    X_train, Y_train, X_test, Y_test = preprocessData(filename, split) # Splitting with split% of data for training

    Ytrain_pred, beta, alpha = trainMethod(X_train, Y_train) # Training with split% training data on 'model' model

    if poly:
        X_test = np.hstack([X_test, X_test**2, X_test**3])
        Y_pred =  alpha + X_test @ beta # Testing 30% data of the data for training on polynomial model
        
    else:
        Y_pred =  alpha + X_test @ beta # Testing split% of the data for training on 'model' model

    print(f'Mean squared error for training data on {modelName} model ({split * 100}% of data for training): ', meanSquaredError(Ytrain_pred, Y_train))
    print(f'Mean squared error for testing data on {modelName} model ({split* 100}% of data for training): ', meanSquaredError(Y_pred, Y_test))
    print('\n')

# ====================== Main ======================

deployModel('housing.txt', 0.3, trainLinearModel, 'Linear', poly=False)
deployModel('housing.txt', 0.6, trainLinearModel, 'Linear', poly=False)
deployModel('housing.txt', 0.3, trainPolynomialModel, 'Polynomial', poly=True)
deployModel('housing.txt', 0.6, trainPolynomialModel, 'Polynomial', poly=True)
deployModel('housing.txt', 0.3, trainL1Model, 'L1 Regressor', poly=False)
deployModel('housing.txt', 0.6, trainL1Model, 'L1 Regressor', poly=False)